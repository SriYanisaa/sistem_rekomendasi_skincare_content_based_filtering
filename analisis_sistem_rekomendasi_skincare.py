# -*- coding: utf-8 -*-
"""Analisis-Sistem-Rekomendasi-Skincare.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kn5w8WWj1bN-gbeiz7poAOdJy7LVoyaV

# **Import Library**
"""

!pip install Sastrawi

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import nltk
import re
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import PCA

"""# **Data Exploration**"""

# Persiapan Dataset
from google.colab import drive
drive.mount('/content/drive')
df = pd.read_csv('/content/drive/MyDrive/DatasetColabNotebooks/data_clean_analytics_femaledaily.csv')
df.head(5)

df.describe()
df.info()

# Memilih Kolom
df = df[['product_name','user_review','product_brand','category', 'subcategory', 'description', 'star_rating', 'is_recommend']]
df.head(5)

# Menggabungkan semua review dari produk yang sama
combined_reviews = df.groupby('product_name')['user_review'].apply(lambda x: ' '.join(x)).reset_index()

# Menyiapkan dataframe hasil penggabungan review
combined_df = pd.DataFrame(combined_reviews, columns=['product_name', 'user_review'])

# Merge dengan dataset asli untuk mendapatkan kolom-kolom lain
combined_df = pd.merge(combined_df, df[['product_name','product_brand', 'category', 'subcategory','description','star_rating','is_recommend']], on='product_name', how='left')

# Menghapus produk dengan nilai duplikat berdasarkan 'product_name'
combined_df = combined_df.drop_duplicates(subset=['product_name'])

# Membuat combined_df menjadi df utama
df = combined_df

# Menampilkan hasil penggabungan review dengan kolom tambahan
df.head()

df.describe()
df.info()

"""# **Data Preprocessing**"""

nltk.download('stopwords')
nltk.download('punkt')
# Define text preprocessing methods
factory = StemmerFactory()
stemmer = factory.create_stemmer()
stop_words = set(stopwords.words('indonesian'))

def remove_emoji(text):
    emoji_pattern = re.compile("["
        u"\U0001F000-\U0001F6FF"  # emoticons & transportasi
        u"\U0001F780-\U0001F7FF"  # simbol, tanda & bendera
        u"\U0001F800-\U0001F8FF"  # emoji surat / katakana
        u"\U0001F900-\U0001F9FF"  # emoji berbagai jenis
        u"\U00002600-\U000026FF"  # simbol matahari & bulan
        u"\U00002700-\U000027BF"  # simbol koin, alat musik, dll.
        u"\U0001F300-\U0001F5FF"  # simbol & markah
        u"\U0001F680-\U0001F6FF"  # transportasi & simbol tempat
                           "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', text)

def preprocess_text(text):
   # Remove emoji
    text = remove_emoji(text)
    # Remove numbers
    text = re.sub(r'\d+', '', text)
    # Case folding
    text = text.lower()
    # Tokenization
    words = nltk.word_tokenize(text)
    # Filtering
    filtered_words = [word for word in words if re.match(r'[a-zA-Z]+', word) and not word in stop_words]
    # Stemming
    stemmed_words = [stemmer.stem(word) for word in filtered_words]
    # Joining the stemmed words back into a single string
    preprocessed_text = " ".join(stemmed_words)
    return preprocessed_text

# Apply the text preprocessing function to the "review" column
df["description_processed"] = df["description"].apply(preprocess_text)

# Apply the text preprocessing function to the "review" column
df["review_processed"] = df["user_review"].apply(preprocess_text)

df

df.to_csv('data_final_clean_femaledaily.csv', index=False)

from google.colab import drive
drive.mount('/content/drive')
df = pd.read_csv('/content/drive/MyDrive/DatasetColabNotebooks/data_final_clean_femaledaily.csv')
df

df.info()

df = df.dropna()

# reset index
df = df.reset_index(drop=True)
df

df.info()

"""# **TF-IDF & Cosine Similarity**"""

# Representasi Fitur
tfidf = TfidfVectorizer()
tfidf_matrix = tfidf.fit_transform(df['description_processed'] + ' ' + df['review_processed'])

print(tfidf_matrix)

"""## Contoh Implementasi Penerapan TF-IDF"""

# Kata-kata yang ingin dihitung TF-nya
target_words = ["bersih", "cocok", "facial", "jerawat", "kering", "kulit"]

# Mengambil indeks kolom yang sesuai dengan kata-kata target
target_word_indices = [tfidf.vocabulary_.get(word) for word in target_words]

# Menghitung TF kata-kata target
tf_scores = tfidf_matrix[:, target_word_indices].toarray()

# Membuat DataFrame untuk menyimpan hasil TF
tf_df = pd.DataFrame(tf_scores, columns=target_words)

# Menambahkan kolom 'Dokumen' ke DataFrame
tf_df['Dokumen'] = range(1, len(df)+1)

# Mengatur 'Dokumen' sebagai indeks
tf_df.set_index('Dokumen', inplace=True)

# Menampilkan DataFrame
display(tf_df)

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer

# Inisialisasi CountVectorizer
vectorizer = CountVectorizer(vocabulary=target_words)

# Menghitung TF kata-kata target
tf_matrix = vectorizer.transform(df['description_processed'] + ' ' + df['review_processed'])

# Membuat DataFrame untuk menyimpan hasil TF
tf_df = pd.DataFrame(tf_matrix.toarray(), columns=target_words)

# Menambahkan kolom 'Dokumen' ke DataFrame
tf_df['Dokumen'] = range(1, len(df)+1)

# Mengatur 'Dokumen' sebagai indeks
tf_df.set_index('Dokumen', inplace=True)

# Menampilkan DataFrame
display(tf_df)

"""## Penerapan Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity
cosine_similarities = cosine_similarity(tfidf_matrix)

print(cosine_similarities)

cosine_df = pd.DataFrame(cosine_similarities)
cosine_df.head()

"""# Recommendation Analysis

## Input Product for Recommendation
"""

similarities = {}

for i in range(len(cosine_similarities)):
    # Now we'll sort each element in cosine_similarities and get the indexes of the product.
    similar_indices = cosine_similarities[i].argsort()[:-50:-1]
    similarities[df['product_name'].iloc[i]] = [(cosine_similarities[i][x], df['product_name'][x], df['product_brand'][x]) for x in similar_indices][1:]

class ContentBasedRecommender:
    def __init__(self, matrix):
        self.matrix_similar = matrix

    def _print_message(self, skincare, recom_skincare):
        rec_items = len(recom_skincare)

        print(f'The {rec_items} recommended product for {skincare} are:')
        for i in range(rec_items):
            print(f"Number {i+1}:")
            print(f"{recom_skincare[i][1]} brand {recom_skincare[i][2]} with {round(recom_skincare[i][0], 3)} similarity score")
            print("--------------------")

    def recommend(self, recommendation):
        # Get product to find recommendations for
        skincare = recommendation['product_name']
        # Get number of product to recommend
        sum_skincare = recommendation['sum_skincare']
        # Get the number of product most similars from matrix similarities
        recom_skincare = self.matrix_similar[skincare][:sum_skincare]
        # print each item
        self._print_message(skincare=skincare, recom_skincare=recom_skincare)

recommedations = ContentBasedRecommender(similarities)

recommendation = {
    "product_name": 'vylea',
    "sum_skincare": 5
}

recommedations.recommend(recommendation)

"""## If Input Multiple Product"""

similarities = {}

for i in range(len(cosine_similarities)):
    similar_indices = cosine_similarities[i].argsort()[:-50:-1]
    similarities[df['product_name'].iloc[i]] = [(cosine_similarities[i][x], df['product_name'][x], df['product_brand'][x]) for x in similar_indices][1:]

class ContentBasedRecommender:
    def __init__(self, matrix):
        self.matrix_similar = matrix

    def _print_message(self, skincare, recom_skincare):
        rec_items = len(recom_skincare)

        print(f'The {rec_items} recommended products for {skincare} are:')
        for i, product in enumerate(recom_skincare, start=1):
            print(f"Number {i}:")
            print(f"{product[1]} brand {product[2]} with {round(product[0], 3)} similarity score")
            print("--------------------")

    def recommend(self, recommendation):
        # Get products to find recommendations for
        skincare_list = recommendation['product_names']
        # Get number of products to recommend
        sum_skincare = recommendation['sum_skincare']

        all_recom_skincare = []
        for skincare in skincare_list:
            if skincare in self.matrix_similar:
                recom_skincare = self.matrix_similar[skincare][:sum_skincare]
                all_recom_skincare.extend(recom_skincare)

        all_recom_skincare = sorted(all_recom_skincare, key=lambda x: x[0], reverse=True)

        print(f"The recommended products based on multiple inputs are:")
        for i, product in enumerate(all_recom_skincare[:sum_skincare], start=1):
            print(f"Number {i}:")
            print(f"{product[1]} brand {product[2]} with {round(product[0], 3)} similarity score")
            print("--------------------")

recommedations = ContentBasedRecommender(similarities)

recommendation = {
    "product_names": ['wardah face wash', 'valenno facial wash', 'vylea'],
    "sum_skincare": 5
}

recommedations.recommend(recommendation)